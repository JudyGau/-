{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformer import vit_base_patch16_224_in21k\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from flask import Flask, jsonify, app, request\n",
    "from PIL import Image\n",
    "from torch import softmax\n",
    "import base64\n",
    "import io\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "weights_path = \"model/output/transformer_zqg.pt\"\n",
    "\n",
    "# 定义预处理函数，将图片进行resize和归一化等操作\n",
    "preprocess = transforms.Compose(\n",
    "    [  # 数据处理\n",
    "        transforms.ToTensor(),  # 转换为张量\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # 归一化处理\n",
    "    ]\n",
    ")\n",
    "# 创建模型实例\n",
    "model = vit_base_patch16_224_in21k(num_classes=20, has_logits=False)\n",
    "# 从.pt文件中加载权重参数\n",
    "weights = torch.load(weights_path)\n",
    "# 应用权重参数到模型实例\n",
    "model.load_state_dict(weights)\n",
    "# 获取模型实例\n",
    "model = model.eval()\n",
    "# 将模型转移至GPU上（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "class_names = [\n",
    "    \"土豆\",\n",
    "    \"茄子\",\n",
    "    \"香菜\",\n",
    "    \"玉米\",\n",
    "    \"青椒\",\n",
    "    \"韭菜\",\n",
    "    \"豌豆\",\n",
    "    \"梨子\",\n",
    "    \"苹果\",\n",
    "    \"西兰花\",\n",
    "    \"蒜苗\",\n",
    "    \"水稻\",\n",
    "    \"小麦\",\n",
    "    \"胡萝卜\",\n",
    "    \"葡萄\",\n",
    "    \"南瓜\",\n",
    "    \"黄瓜\",\n",
    "    \"香蕉\",\n",
    "    \"西红柿\",\n",
    "    \"西瓜\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = (\n",
    "    \"dataset\\\\train\\\\葡萄\\\\【AI数字艺术】粉红色背景下的葡萄特写镜头VCG211447985488.jpg\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# @app.route(\"/predict\", methods=[\"POST\"])\n",
    "\n",
    "# def predict():\n",
    "print(\"如下是请求内容：\")\n",
    "print(request.get_json())\n",
    "\n",
    "img_base64 = request.get_json()[\"imgdata\"]\n",
    "\n",
    "image = base64.b64decode(img_base64)\n",
    "\n",
    "image = Image.open(io.BytesIO(image))\n",
    "\n",
    "image_tensor = preprocess(image).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    pre = model(image_tensor)\n",
    "    print(pre)\n",
    "\n",
    "    pre = softmax(pre, dim=1).detach().cpu().numpy()[0]\n",
    "    print(pre)\n",
    "\n",
    "print(np.argsort(pre))\n",
    "\n",
    "y_hat = np.argsort(pre)[::-1][:5]\n",
    "\n",
    "print(y_hat)\n",
    "\n",
    "result = []\n",
    "\n",
    "for y in y_hat:\n",
    "\n",
    "    name = class_names[y]\n",
    "    print(name)\n",
    "\n",
    "    score = str(pre[y])\n",
    "    print(score)\n",
    "\n",
    "    result.append([name, score])\n",
    "\n",
    "print(result)\n",
    "\n",
    "\n",
    "#     return jsonify(\n",
    "\n",
    "#         {\"eror_code\": \"undefiened\", \"error_msg\": \"未知错误\", \"results\": result}\n",
    "#     )\n",
    "\n",
    "\n",
    "\n",
    "# # 启动服务器\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     app.run(host=\"0.0.0.0\", port=5000)\n",
    "\n",
    "\n",
    "\n",
    "# # 使用模型进行预测，并显示预测结果\n",
    "\n",
    "# with torch.no_grad():\n",
    "\n",
    "#     output = model(image_tensor)\n",
    "\n",
    "#     _, predicted = torch.max(output, 1)\n",
    "\n",
    "#     class_name = class_names[predicted.item()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
